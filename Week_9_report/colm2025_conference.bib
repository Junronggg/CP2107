@article{deepseek2024r1,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek Team},
  journal={arXiv preprint arXiv:2501.12948},
  year={2024},
  url={https://arxiv.org/abs/2501.12948}
}

@misc{liu2025understandingr1zeroliketrainingcritical,
      title={Understanding R1-Zero-Like Training: A Critical Perspective}, 
      author={Zichen Liu and Changyu Chen and Wenjun Li and Penghui Qi and Tianyu Pang and Chao Du and Wee Sun Lee and Min Lin},
      year={2025},
      eprint={2503.20783},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.20783}, 
}

@article{deepseek2023v3,
  title={DeepSeek-V3: Towards Scalable and Capable Multilingual Language Models},
  author={DeepSeek Team},
  journal={arXiv preprint arXiv:2312.10301},
  year={2023},
  url={https://arxiv.org/abs/2312.10301}
}

@article{schulman2017ppo,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017},
  url={https://arxiv.org/abs/1707.06347}
}

@inproceedings{wei2022cot,
  title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022},
  url={https://arxiv.org/abs/2201.11903}
}

@inproceedings{jaques2023tuning,
  title={Tuning Language Models as Training Data for Reward Models},
  author={Jaques, Natasha and Mu, Jonathan and Ye, Ziming and Li}
}
